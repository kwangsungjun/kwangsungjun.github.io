<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>home</title>
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-106338466-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Kwang-Sung Jun</div>
<div class="menu-item"><a href="index.html" class="current">home</a></div>
<div class="menu-item"><a href="publication.html">publications</a></div>
<div class="menu-item"><a href="teaching.html">teaching</a></div>
<div class="menu-item"><a href="personal.html">personal&nbsp;stuff</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>home</h1>
</div>
<table class="imgtable"><tr><td>
<img src="./imgs/kwang-sung_jun_pic_2.jpg" alt="profile_pic" width="240px" height="HEIGHTpx" />&nbsp;</td>
<td align="left"><p>Assistant Professsor</br>
Computer Science</br>
Statistics GIDP, Applied Math GIDP (affiliated)</br>
University of Arizona</br></p>
<p>kjun å† cs ∂ø† arizona ∂ø† edu</br>
746 Gould-Simpson, 1040 E. 4th St., Tucson, AZ 85721, USA </br>
<a href="https://scholar.google.com/citations?user=VgvC7o8AAAAJ&amp;hl=en" target=&ldquo;blank&rdquo;>Google scholar</a></br>
<a href="./data/kjun-cv.pdf" target=&ldquo;blank&rdquo;>CV</a></p>
</td></tr></table>
<p><font color=D95B43><b>I am actively recruiting PhD students. Email me! </b></font></p>
<p>My research is centered around sequential decision-making in feedback loops (i.e., the multi-armed bandit problem) and online learning.
I also had some fun in the past with machine learning applied to psychology.  
I was previously a postdoc with <a href="http://francesco.orabona.com/" target=&ldquo;blank&rdquo;>Francesco Orabona</a> at Boston University.
Before then, I spent 9 years at UW-Madison for a PhD degree with <a href="http://pages.cs.wisc.edu/~jerryzhu/" target=&ldquo;blank&rdquo;>Xiaojin (Jerry) Zhu</a> and a postdoc position at <a href="https://discovery.wisc.edu/" target=&ldquo;blank&rdquo;>Wisconsin Institute for Discovery</a> with <a href="http://nowak.ece.wisc.edu" target=&ldquo;blank&rdquo;>Robert Nowak</a>, <a href="http://willett.ece.wisc.edu/" target=&ldquo;blank&rdquo;>Rebecca Willett</a>, and <a href="http://pages.cs.wisc.edu/~swright/" target=&ldquo;blank&rdquo;>Stephen Wright</a>.</p>
<h2>news</h2>
<ul>
<li><p>11/19: In Spring 2020, I will be teaching <a href="./20.1.csc665/index.html" target=&ldquo;blank&rdquo;>CSC 665 Online Learning and Multi-armed Bandits</a>.</p>
</li>
<li><p>10/19: Chicheng Zhang, Jason Pacheco, and I are organizing a <a href="https://sites.google.com/view/ua-mlrg/" target=&ldquo;blank&rdquo;>machine learning reading group</a> at UA.</p>
</li>
<li><p>10/19: Our paper on kernel regression paper is accepted at NeurIPS&rsquo;19.</p>
</li>
<li><p>10/19: Our paper on parameter-free SGD with local differential privacy is accepted to PriML&rsquo;19 (worshop at NeurIPS).</p>
</li>
</ul>
<h2>multi-armed bandit</h2>
<p>Multi-armed bandit is a <i>state-less</i> version of the reinforcement learning (RL).
But why study an easier version of RL while RL seems to be solving all the problems these day?
Bandits are simpler and thus have strong theoretical guarantees and yet have abundant real-world applications.
Furthermore, developments in bandits can potentially improve RL algorithms, either transferring ideas from bandits to RL or directly use bandits for Monte Carlo planning in MDP (e.g., the Monte Carlo tree search algorithm used in AlphaGo was originated from <a href="https://dl.acm.org/doi/10.1007/11871842_29" target=&ldquo;blank&rdquo;>this paper</a>).</p>
<p>Informally speaking, bandits learn to make better decisions over time in a feedback-loop.
The decisions necessarily affect the feedback information, and the feedback data collected so far is no longer i.i.d.; most traditional learning guarantees do not apply.</p>
<p>Bandits are actively being studied in both <a href="https://arxiv.org/abs/1204.5721" target=&ldquo;blank&rdquo;>theory</a> and <a href="http://rob.schapire.net/papers/www10.pdf" target=&ldquo;blank&rdquo;>applications</a> including <a href="https://mwtds.azurewebsites.net/" target=&ldquo;blank&rdquo;>deployable web service</a>. 
Also, the cartoon caption contest of New Yorker is currently using a multi-armed bandit algorithm to efficiently crowdsource caption evaluations (<a href="http://nextml.org/2015/12/04/new-yorker.html" target=&ldquo;blank&rdquo;>this article</a>)!</p>
<h2>talks</h2>
<ul>
<li><p>05/20: At Los Alamos - Arizona Days Conference, &ldquo;Adaptive data collection for accelerating discovery rates.&rdquo;</p>
</li>
<li><p>09/19: At TRIPODS seminar, the U of Arizona, &ldquo;Adaptive data collection for accelerating discovery rates.&rdquo;  </p>
</li>
<li><p>09/19: At TRIPODS RWG6, the U of Arizona, &ldquo;Accelerating discovery rate in adaptive experiments via bandits with low-rank structure.&rdquo; </p>
</li>
<li><p>07/19: At Microsoft New England, &ldquo;Accelerating discovery rate in adaptive experiments via bandits with low-rank structure.&rdquo;</p>
</li>
<li><p>04/19: At the U of Arizona, &ldquo;Accelerating discovery rate in adaptive experiments via bandits with low-rank structure.&rdquo;</p>
</li>
<li><p>10/18: At Open AIR: Industry Open House, Boston University, &ldquo;Adapting to changing environments in online learning.&rdquo;</p>
</li>
<li><p>10/17: At <a href="http://silo.ece.wisc.edu/web/" target=&ldquo;blank&rdquo;>SILO</a>, &ldquo;Scalable Generalized Linear Bandits: Online Computation and Hashing.&rdquo; <a href="http://silo.ece.wisc.edu/web/content/seminar/id/243" target=&ldquo;blank&rdquo;>[abstract]</a></p>
</li>
<li><p>04/17: At <a href="http://www.aistats.org/aistats2017//schedule.html" target=&ldquo;blank&rdquo;>AISTATS</a>, &ldquo;Improved Strongly Adaptive Online Learning using Coin Betting.&rdquo;</p>
</li>
<li><p>06/16: At <a href="http://cpcp.wisc.edu/" target=&ldquo;blank&rdquo;>CPCP</a> Annual Retreat, &ldquo;Multi-Armed Bandit Algorithms and Applications to Experiment Selection.&rdquo; <a href="http://cpcp.wisc.edu/resources/cpcp-retreat-2016-multi-armed-bandit-algorithms-and-applications-to-experiment-selection-kwang-sung-jun-6-30-2016" target=&ldquo;blank&rdquo;>[abstract &amp; video]</a></p>
</li>
<li><p>03/16: At <a href="http://silo.ece.wisc.edu/web/" target=&ldquo;blank&rdquo;>SILO</a>, &ldquo;Top Arm Identification in Multi-Armed Bandits with Batch Arm Pulls.&rdquo; <a href="http://silo.ece.wisc.edu/web/content/seminar/id/198" target=&ldquo;blank&rdquo;>[abstract &amp; video]</a></p>
</li>
<li><p>03/16: At <a href="http://eng.ssu.ac.kr/web/eng/edu_a_01_07_a" target=&ldquo;blank&rdquo;>Soongsil University</a>, two talks on human memory search.</p>
</li>
<li><p>06/16: At <a href="http://icml.cc/2016/" target=&ldquo;blank&rdquo;>ICML</a>, &ldquo;Anytime Exploration for Multi-armed Bandits using Confidence Information.&rdquo; <a href="http://techtalks.tv/talks/anytime-exploration-for-multi-armed-bandits-using-confidence-information/62425/" target=&ldquo;blank&rdquo;>[video]</a></p>
</li>
<li><p>11/15: At HAMLET (interdisciplinary seminar series at UW-Madison), &ldquo;Measuring semantic structure from verbal fluency data with the initial-visit-emitting (INVITE) random walk.&rdquo;</p>
</li>
<li><p>03/15: At <a href="http://www.ttic.edu/" target=&ldquo;blank&rdquo;>TTIC</a>, &ldquo;Learning from Human-Generated Lists.&rdquo;</p>
</li>
<li><p>06/13: At <a href="http://icml.cc/2013/?page_id=47" target=&ldquo;blank&rdquo;>ICML</a>, &ldquo;Learning from Human-Generated Lists.&rdquo; <a href="http://techtalks.tv/talks/learning-from-human-generated-lists/58261/" target=&ldquo;blank&rdquo;>[video]</a></p>
</li>
</ul>
<h2>services</h2>
<ul>
<li><p>Program Committee / Reviewer: AISTATS&rsquo;20 reviewer, AAAI&rsquo;20 Area Chair, ICML&rsquo;19, COLT&rsquo;19 (subreviewer), IJCAI&rsquo;19, NeurIPS&rsquo;19, IEEE Transactions on Signal Processing, ICML&rsquo;19, AISTATS&rsquo;19 ,NeurIPS&rsquo;18, AISTATS&rsquo;18, AAAI&rsquo;18, NeurIPS&rsquo;17, ICML&rsquo;17, COLT&rsquo;17 (subreviewer), AISTATS&rsquo;17, ICML&rsquo;16.</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2020-05-27 15:29:51 MST, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
