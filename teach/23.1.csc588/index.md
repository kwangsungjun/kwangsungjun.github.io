# CSC 588: Machine Learning Theory - Spring 2023

This course provides an introduction to the theoretical aspects of machine learning. Students will learn how and when machine learning is possible/impossible as well as various algorithms with theoretical guarantees under minimal assumptions. Specifically, the course offers formulation of learning environments (e.g., batch and online settings, stochastic and adversarial worlds with possibly limited feedback), fundamental limits of learning in these environments, various algorithms concerning sample efficiency, computational efficiency, and generality. Throughout, students will not only learn fundamental tools upholding the current understanding of machine learning systems in the research community but also develop skills of adapting these techniques to their own research needs such as developing new algorithms for large-scale, data-driven applications.

### Syllabus

Here is the [syallabus updated on 01/11/2023](./data/23s588 syllabus.pdf). Further adjustments will be available in D2L.

### Logistics info

 * **Tuesdays and Thursdays, 9:30am-10:45am**
<!-- * **(TODO)** [Piazza link](http://piazza.com/arizona/spring2020/csc665) access code: bandits -->
<!-- * [Gradescope](https://www.gradescope.com/courses/163532) entry code: MXD4D2 -->
 * Please find other information from the D2L and the syllabus.

[//]: # ()

### Instructor

 * [Kwang-Sung Jun](https://kwangsungjun.github.io/)
 * k\[lastname\]@cs.arizona.edu
 * Gould-Simpson Rm 746
 * Office hour: Tuesdays 4-5pm

### Textbook

There is no designated textbook for this course. Much of the course materials will be based on these books:

[Understanding machine learning: from theory to algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/) by Shai Shalev-Shwartz and Shai Ben-David (SSBD)

[A Modern Introduction to Online Learning](https://arxiv.org/abs/1912.13213) by Francesco Orabona (O)

[Bandit algorithms](https://tor-lattimore.com/downloads/book/book.pdf) by Tor Lattimore and Csaba Szepesvari (LS)

[Reinforcement Learning: Theory and Algorithms](https://rltheorybook.github.io/rltheorybook_AJKS.pdf) by Alekh Agarwal, Nan Jiang, Sham Kakade, and Wen Sun (AJKS)

Other useful resources

 * Here are some excellent notes for [probability review](http://cs229.stanford.edu/section/cs229-prob.pdf) and [linear algebra review](http://cs229.stanford.edu/section/cs229-linalg.pdf).
 * You should have no difficulty in Python programming.
 * You may also find [The matrix cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf), [The Probability and Statistics Cookbook](http://statistics.zone/) useful, and [Calculus cheatsheet](https://tutorial.math.lamar.edu/pdf/calculus_cheat_sheet_all.pdf).

### Schedule

The following is a rough schedule.
Please see D2L for a more detailed and calibrated schedule.

|#  | | &nbsp;&nbsp;Topics | Readings |  | Homework |
|---:|-|:-------------|:---:|:---:|:---:|
| 1: 01/12 || intro                                                     |        | | HW1 |
| 2: 01/17 || concentration of measure                                  |        | | |
| 3: 01/19 || the statistical learning/PAC framework                    |        | |     |
| 4: 01/24 || VC Theory                                                 |        | | |
| 5: 01/26 ||                                                           |        | |     |
| 6: 01/31 || Rademacher complexity                                     |        | | |
| 7: 02/02 || Support vector machine, kernel methods, margin bounds.    |        | | HW2 |
| 8: 02/07 || .                                                         |        | |     |
| 9: 02/09 || Model selection: Structural risk minimization             |        | | |
|10: 02/14 || Boosting                                                  |        | | |
|11: 02/16 || .                                                         |        | | HW3    |
|12: 02/21 || Backgrounds on convex functions                           |        | | |
|13: 02/23 || Regularization and stability                              |        | | |
|14: 02/28 || .                                                         |        | | |
|15: 03/02 || Online classification                                     |        | |         |
|16: 03/07 || (spring recess)                                           |        | | |
|17: 03/09 || .                                                         |        | |     |
|18: 03/14 || Online convex optimization (OCO)                                |        | | |
|19: 03/16 || Follow the regularized leader                             |        | | |
|20: 03/21 || Online mirror descent                                     |        | |     |
|21: 03/23 || OCO for strongly-convex/exp-concave functions             |        | | |
|22: 03/28 || Prediction with expert advice                             |        | | |
|23: 03/30 || .                                                         |        | | HW4 |
|22: 04/04 || Adversarial multi-armed bandits                                                           |        | | |
|23: 04/06 || Stochastic multi-armed bandits                               |        | |     |
|24: 04/11 || .                                                          |        | | |
|25: 04/13 || Stochastic linear bandits                                                          |        | | |
|26: 04/18 || .                                                          |        | |     |
|27: 04/20 || Online reinforcement learning in Markov decision processes                                                          |        | | |
|28: 04/25 || .                                                          |        | | |
|29: 04/27 || project presentation                                                            |  | | |
|30: 05/02 || .                                    |  | | |
|  : 05/04 || final project due                                                          |  | |  |
|  : 05/09 || final exam                                                             |   |   |   |
|<img width=20/>|<img width=10/>| <img width=400/>                    | <img width=200/> |<img width=100/> | <img width=100/>  |




</br>
</br>
</br>
</br>
</br>
