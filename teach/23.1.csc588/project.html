<!doctype html>
<html >
<head>

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!--[if lt IE 9]>
                <script src="http://css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script>
        <![endif]-->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />

  <link rel="stylesheet" type="text/css" href="/templates/pandoc-bootstrap-adaptive-template/tufte.css" />

   <link href="https://vjs.zencdn.net/5.4.4/video-js.css" rel="stylesheet" />



<script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
<script type='text/javascript' src='/templates/pandoc-bootstrap-adaptive-template/menu/js/jquery.cookie.js'></script>
<script type='text/javascript' src='/templates/pandoc-bootstrap-adaptive-template/menu/js/jquery.hoverIntent.minified.js'></script>
<script type='text/javascript' src='/templates/pandoc-bootstrap-adaptive-template/menu/js/jquery.dcjqaccordion.2.7.min.js'></script>

<link href="/templates/pandoc-bootstrap-adaptive-template/menu/css/skins/blue.css" rel="stylesheet" type="text/css" />
<link href="/templates/pandoc-bootstrap-adaptive-template/menu/css/skins/graphite.css" rel="stylesheet" type="text/css" />
<link href="/templates/pandoc-bootstrap-adaptive-template/menu/css/skins/grey.css" rel="stylesheet" type="text/css" />

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  <script src="/templates/pandoc-bootstrap-adaptive-template/script.js"></script>

    <script src="/bower_components/sticky-kit/jquery.sticky-kit.js "></script>
  <meta name="generator" content="pandoc" />
  <title>CSC 588 Spring 2023: Project</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="bootstrap.css" />
</head>
<body>

<!--
    <div class="navbar navbar-static-top">
    <div class="navbar-inner">
      <div class="container">
        <span class="doc-title">CSC 588 Spring 2023: Project</span>
        <ul class="nav pull-right doc-info">
                            </ul>
      </div>
    </div>
  </div>
  -->
  <div class="container">
    <div class="row">
            <div class="span12">
            <nav class="navbar navbar-default">
              <div class="container-fluid">
                <!-- Brand and toggle get grouped for better mobile display -->
                <div class="navbar-header">
                  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                  </button>
                  <a class="navbar-brand" href="index.html">CSC 588</a>
                </div>

                <!-- Collect the nav links, forms, and other content for toggling -->
                <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                  <ul class="nav navbar-nav">
                    <li><a href="project.html">Project</a></li>
                    <!--        <li><a href="project.html">Project</a></li>-->
                  </ul>
                </div><!-- /.navbar-collapse -->
              </div><!-- /.container-fluid -->
            </nav>
            <h3
            id="csc-588-machine-learning-theory-spring-2023-final-project">CSC
            588 Machine Learning Theory (Spring 2023): Final
            Project</h3>
            <h3 id="general-information">General information</h3>
            <p>(credit: adapted from <a
            href="https://zcc1307.github.io/courses/csc588sp22/project.html">Chicheng
            Zhang’s course</a> and <a
            href="https://cseweb.ucsd.edu/classes/fa12/cse291-b/projectinfo.html">project
            guidelines of Kamalika Chaudhuri’s Machine Learning Theory
            course</a>)</p>
            <p>You can choose to do one of the following types of
            projects:</p>
            <ul>
            <li><p><strong>Literature survey.</strong> You need to
            choose a topic (see below for some ideas) and read at least
            6 papers on this topic. Be sure to select papers
            judiciously, so that both classical and state-of-the-art
            perspectives are covered. Sometimes the
            <em>Introduction</em> and <em>Related Work</em> sections of
            recent papers will help you find most relevant papers. When
            you are in doubt whether a paper is relevant, come to my
            office hour and we can figure this out. It is important that
            you read the papers <em>critically</em>, and form your own
            opinions on the papers you read: What are the major open
            problems in this area? What are the pros and cons of
            existing approaches? (The latter can be summarized with a
            table, for example.)</p></li>
            <li><p><strong>Implementation.</strong> You are asked to
            conduct experiments on deploying theoretically-principled
            learning algorithms onto synthetic or real data. If you
            choose to implement an algorithm from a paper that does not
            have theorem statements (or ‘trivial’ theorems with
            straightforward proofs), this may not be a good fit for this
            course. In addition, we ask that your experiment must be
            used to support theoretical results obtained in the paper.
            <em>You are expected to conduct critical analyses on your
            experimental results</em>, by answering questions such as:
            how well do the experimental results agree with the proposed
            theory? If the results do not agree well with the theory,
            which assumption in the theory are violated? You should also
            provide a list of datasets you are using.</p></li>
            <li><p><strong>Research.</strong> Research projects, roughly
            speaking, can have two styles: first, attacking an existing
            open problem in the literature; second, formulating a new
            (theoretically interesting and practically relevant) problem
            and proposing a feasible solution. Completing a research
            project naturally requires a thorough literature survey in
            the first place - you need to ensure that your approach or
            model has never been proposed in prior works. <em>Note that
            a research project may require substantially larger amount
            of time compared to the first two project types, so I
            suggest being careful with this choice if you already have a
            heavy workload this semester.</em> The upside of a research
            project is that your work may result in
            publications.</p></li>
            </ul>
            <h3 id="project-timelines">Project timelines</h3>
            <ul>
            <li><p><strong>Project Proposal.</strong> A 2-page project
            proposal. The project proposal should consist of the
            following parts:</p>
            <ul>
            <li>a brief description of the project topic</li>
            <li>a justification why this is relevant in learning
            theory</li>
            <li>for literature survey, have a planned reading list; for
            implementation, have a list of algorithms to implement and a
            set of driving questions to answer with the experiments; for
            research, have a list of research questions to attack (It
            would be good to have one concrete question, and list a few
            important sub-questions toward solving it.)</li>
            </ul></li>
            </ul>
            <p>If you need help with choosing a project, please schedule
            an appointment with me and I will help you brainstorm
            one.</p>
            <ul>
            <li><p><strong>Final Report.</strong> A 4-page summary of
            the project (8 pages for teams). You can use appendix if
            there are details you want to share. The report will be
            judged on both clarity and quality. The report needs to be
            typeset by LaTeX.</p>
            <ul>
            <li>For literature survey, provide a critical summary of the
            papers you have read; discuss the connections among these
            papers, and their impacts to broader field.</li>
            <li>For implementation projects, present your experimental
            results, and check whether the experimental results agree
            with theory.</li>
            <li>For research projects, your report should have a
            <em>Related work</em> section discussing why your result is
            novel compared to existing work. You should also describe
            your approach (if you have a new algorithm, provide its
            pseudocode; if you propose a new learning model, define new
            key concepts in your model; if you show your proposed
            algorithm has good performance guarantee, write down a
            theorem statement on it.)</li>
            </ul></li>
            <li><p><strong>Final Presentation.</strong> It will be 10-15
            minutes presentation.</p>
            <ul>
            <li>Please please make sure the problem definition is well
            explained.</li>
            <li>The evaluation will be based more on how you are
            presenting than what you are presenting, but please note
            that the distinction can be blurred if what you are
            presenting is already unclear.</li>
            </ul></li>
            </ul>
            <h3 id="useful-tips">Useful tips</h3>
            <p>Here are some useful tips for:</p>
            <ul>
            <li>reading papers: <a
            href="http://ccr.sigcomm.org/online/files/p83-keshavA.pdf">How
            to read a paper</a> by Prof. Srinivasan Keshav; <a
            href="https://cs.stanford.edu/~rishig/courses/ref/paper-reading-technical.pdf">Reading
            in Algorithms: Paper-Reading Survival Kit</a> by Prof. Tim
            Roughgarden.</li>
            <li>presentations: <a
            href="https://people.eecs.berkeley.edu/~jrs/speaking.html">Giving
            an Academic Talk</a> by Prof. Jonathan Shewchuk; <a
            href="https://cseweb.ucsd.edu//~elkan/254/speaking.html">Notes
            on Giving a Research Talk</a> by Prof. Charles Elkan.</li>
            </ul>
            <h3 id="project-ideas">Project ideas</h3>
            <p>Below are a few example research directions in machine
            learning theory, each with a few “seed papers”; you can use
            the related work section in these papers, or use the “cited
            by” functionality in e.g. <a
            href="https://scholar.google.com/">google scholar</a> to
            find more papers on the same topic. Please also refer to
            proceeding pages of recent machine learning / learning
            theory conferences and workshops for more project ideas,
            such as:</p>
            <ul>
            <li><a
            href="http://proceedings.mlr.press/v97/">ICML</a>,</li>
            <li><a
            href="http://proceedings.mlr.press/v99/">COLT</a>,</li>
            <li><a href="https://papers.nips.cc/">NeurIPS</a> ,</li>
            <li><a
            href="http://proceedings.mlr.press/v108/">AISTATS</a>,</li>
            <li><a
            href="http://proceedings.mlr.press/v117/">ALT</a>,</li>
            <li><a
            href="https://sites.google.com/view/mlwithguarantees/accepted-papers?authuser=0">NeurIPS
            Workshop on Machine Learning with Guarantees</a>.</li>
            </ul>
            <p>Similiar courses in other institutions may also have nice
            collections of interesting project ideas, for example:</p>
            <ul>
            <li><a
            href="http://alekhagarwal.net/bandits_and_rl/#view3">Bandits
            and RL by Alekh Agarwal and Alex Slivkins</a></li>
            <li><a
            href="http://www.cs.cmu.edu/~avrim/ML07/projects.html">Foundations
            of Machine Learning and Data Science by Nina Balcan and
            Avrim Blum</a></li>
            <li><a
            href="https://nanjiang.cs.illinois.edu/cs598project/">Statistical
            Reinforcement Learning by Nan Jiang</a></li>
            <li><a
            href="https://haipeng-luo.net/courses/CSCI699/project.html">Introduction
            to Online Learning by Haipeng Luo</a></li>
            </ul>
            <h4 id="active-learning">Active learning</h4>
            <h5
            id="label-complexity-analysis-of-pac-active-learning">Label
            complexity analysis of PAC active learning</h5>
            <ul>
            <li>M.F. Balcan, A. Beygelzimer, J. Langford. Agnostic
            active learning. ICML 2006.</li>
            <li>Sanjoy Dasgupta, Daniel J. Hsu, Claire Monteleoni. A
            general agnostic active learning algorithm. NeurIPS
            2007.</li>
            <li>S. Hanneke. Theory of Disagreement-Based Active
            Learning. Foundations and Trends in Machine Learning.
            2014.</li>
            <li>M.F. Balcan and P. Long. Active and Passive Learning of
            Linear Separators under Log-concave Distributions. COLT
            2013.</li>
            <li>Chicheng Zhang and Kamalika Chaudhuri. Beyond
            Disagreement-Based Agnostic Active Learning. 2014.</li>
            <li>Tzu-Kuo Huang, Alekh Agarwal, Daniel J. Hsu, John
            Langford, Robert E. Schapire. Efficient and Parsimonious
            Agnostic Active Learning. NeurIPS 2015.</li>
            </ul>
            <h5 id="nonparametric-active-learning">Nonparametric active
            learning</h5>
            <ul>
            <li>Sanjoy Dasgupta and Daniel Hsu. Hierarchical sampling
            for active learning. ICML 2008.</li>
            <li>R. Urner, S. Wulff, S. Ben-David, PLAL: Cluster-based
            Active Learning. COLT 2013.</li>
            <li>Alexandra Carpentier, Andrea Locatelli, Samory Kpotufe,
            Adaptivity to Noise Parameters in Nonparametric Active
            Learning. COLT 2017.</li>
            <li>Alexandra Carpentier, Andrea Locatelli, Samory Kpotufe.
            An Adaptive Strategy for Active Learning with Smooth
            Decision Boundary. ALT 2018.</li>
            <li>Rui M Castro and Robert D Nowak. Minimax bounds for
            active learning. IEEE Transactions on Information Theory,
            2008.</li>
            <li>Stanislav Minsker. Plug-in approach to active learning.
            Journal of Machine Learning Research, 2012.</li>
            <li>A. Kontorovich, S. Sabato, R. Urner. Active
            nearest-neighbor learning in metric spaces. JMLR, 2017.</li>
            </ul>
            <h5 id="other-new-topics">Other new topics</h5>
            <ul>
            <li>Akshay Krishnamurthy, Alekh Agarwal, Tzu-Kuo Huang, Hal
            Daume III, John Langford. Active Learning for Cost-Sensitive
            Classification. ICML 2017.</li>
            <li>Mina Karzand, Robert D. Nowak. MaxiMin Active Learning
            in Overparameterized Model Classes. Allerton 2019.</li>
            <li>Daniel M. Kane, Shachar Lovett, Shay Moran, Jiapeng
            Zhang. Active classification with comparison queries. FOCS
            2017.</li>
            </ul>
            <h4
            id="efficient-noise-tolerant-pac-learning-of-specific-hypothesis-classes-e.g.-linear-classifiers">Efficient,
            noise tolerant PAC learning of specific hypothesis classes
            (e.g. linear classifiers)</h4>
            <h5 id="positive-results">Positive results</h5>
            <ul>
            <li>Avrim Blum, Alan M. Frieze, Ravi Kannan, and Santosh S.
            Vempala. A polynomial-time algorithm for learning noisy
            linear threshold functions. FOCS 1996.</li>
            <li>Pranjal Awasthi, Maria Florina Balcan, and Philip M
            Long. The power of localization for efficiently learning
            linear separators with noise. JACM 2017.</li>
            <li>Pranjal Awasthi, Maria-Florina Balcan, Nika Haghtalab,
            and Hongyang Zhang. Learning and 1-bit compressed sensing
            under asymmetric noise. COLT 2016.</li>
            <li>Ilias Diakonikolas, Themis Gouleakis, and Christos
            Tzamos. Distribution-independent PAC learning of halfspaces
            with massart noise. NeurIPS 2019.</li>
            <li>Ilias Diakonikolas, Vasilis Kontonis, Christos Tzamos,
            and Nikos Zarifis. Learning halfspaces with massart noise
            under structured distributions. COLT 2020.</li>
            <li>Chicheng Zhang, Jie Shen, Pranjal Awasthi, Efficient
            active learning of sparse halfspaces with arbitrary bounded
            noise. NeurIPS 2020.</li>
            <li>Ilias Diakonikolas, Daniel M. Kane, Vasilis Kontonis,
            Christos Tzamos, Nikos Zarifis. A Polynomial Time Algorithm
            for Learning Halfspaces with Tsybakov Noise. arXiv
            2020.</li>
            <li>Sitan Chen, Frederic Koehler, Ankur Moitra, Morris Yau.
            Classification Under Misspecification: Halfspaces,
            Generalized Linear Models, and Connections to Evolvability.
            NeurIPS 2020.</li>
            </ul>
            <h5 id="computational-hardness">Computational hardness</h5>
            <ul>
            <li>Venkatesan Guruswami and Prasad Raghavendra. Hardness of
            learning halfspaces with noise. SIAM Journal on Computing,
            2009.</li>
            <li>Vitaly Feldman, Parikshit Gopalan, Subhash Khot, and
            Ashok Kumar Ponnuswami. New results for learning noisy
            parities and halfspaces. FOCS 2006.</li>
            <li>Adam Klivans and Pravesh Kothari. Embedding Hard
            Learning Problems Into Gaussian Space. APPROX/RANDOM
            2014.</li>
            <li>Ilias Diakonikolas, Daniel M. Kane. Hardness of Learning
            Halfspaces with Massart Noise. arXiv 2020.</li>
            </ul>
            <h4 id="adversarial-robustness">Adversarial robustness</h4>
            <ul>
            <li>Robustness of classifiers: from adversarial to random
            noise. Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli,
            Pascal Frossard. NIPS 2016.</li>
            <li>Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt,
            Dimitris Tsipras, Adrian Vladu. Towards Deep Learning Models
            Resistant to Adversarial Attacks. ICLR 2018.</li>
            <li>Aditi Raghunathan, Jacob Steinhardt, Percy Liang.
            Certified Defenses against Adversarial Examples. ICLR
            2018.</li>
            <li>Yizhen Wang, Somesh Jha, Kamalika Chaudhuri. Analyzing
            the Robustness of Nearest Neighbors to Adversarial Examples.
            ICML 2018.</li>
            <li>Sébastien Bubeck, Eric Price, Ilya Razenshteyn.
            Adversarial examples from computational constraints. NeurIPS
            2018.</li>
            <li>Daniel Cullina, Arjun Nitin Bhagoji, Prateek Mittal.
            PAC-learning in the presence of evasion adversaries. NeurIPS
            2018.</li>
            <li>Saeed Mahloujifa and Mohammad Mahmoody. Can
            Adversarially Robust Learning Leverage Computational
            Hardness? ALT 2019.</li>
            <li>Omar Montasser, Steve Hanneke, Nathan Srebro. VC Classes
            are Adversarially Robustly Learnable, but Only Improperly.
            COLT 2019.</li>
            </ul>
            <h4 id="bandit-theory">Bandit theory</h4>
            <h5
            id="general-introduction-see-the-chapters-in-the-books-for-topic-ideas">General
            introduction (see the chapters in the books for topic
            ideas)</h5>
            <ul>
            <li>Sébastien Bubeck, Nicolò Cesa-Bianchi. Regret Analysis
            of Stochastic and Nonstochastic Multi-armed Bandit Problems.
            Foundations and Trends in Machine Learning. 2012.</li>
            <li>Aleksandrs Slivkins. Introduction to Multi-Armed
            Bandits. Foundations and Trends in Machine Learning.</li>
            <li>Tor Lattimore and Csaba Szepesvári. Bandit Algorithms.
            Cambridge University Press.</li>
            </ul>
            <h5 id="continuum-armed-bandits">Continuum-armed
            Bandits</h5>
            <ul>
            <li>Robert Kleinberg. Nearly Tight Bounds for the
            Continuum-ArmedBandit Problem. NeurIPS 2004.</li>
            <li>Robert Kleinberg, Aleksandrs Slivkins, Eli Upfal.
            Multi-Armed Bandits in Metric Spaces. STOC 2008.</li>
            <li>Sébastien Bubeck, Rémi Munos, Gilles Stoltz, Csaba
            Szepesvari. X-armed Bandits. JMLR 2011.</li>
            <li>Rémi Munos. From Bandits to Monte-Carlo Tree Search: The
            Optimistic Principle Applied to Optimization and Planning.
            Foundations and Trends in Machine Learning. 2014.</li>
            <li>Andrea Locatelli, Alexandra Carpentier. Adaptivity to
            Smoothness in X-armed bandits. COLT 2018.</li>
            <li>Hedi Hadiji. Polynomial Cost of Adaptation for X-Armed
            Bandits. NeurIPS 2019.</li>
            <li>Akshay Krishnamurthy, John Langford, Aleksandrs
            Slivkins, Chicheng Zhang. Contextual Bandits with Continuous
            Actions: Smoothing, Zooming, and Adapting. COLT 2019.</li>
            </ul>
            <h5
            id="contextual-bandits-via-reduction-to-multiclass-classification">Contextual
            bandits via reduction to multiclass classification</h5>
            <ul>
            <li>John Langford and Tong Zhang The Epoch-Greedy Algorithm
            for Contextual Multi-armed Bandits. NeurIPS 2007.</li>
            <li>Miroslav Dudik, Daniel Hsu, Satyen Kale, Nikos
            Karampatziakis, John Langford, Lev Reyzin, and Tong Zhang,
            Efficient Optimal Learning for Contextual Bandits, UAI
            2011.</li>
            <li>Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford,
            Lihong Li, Robert E. Schapire. Taming the Monster: A Fast
            and Simple Algorithm for Contextual Bandits. ICML 2014.</li>
            </ul>
            <h5
            id="contextual-bandits-with-general-regressor-classes">Contextual
            bandits with general regressor classes</h5>
            <ul>
            <li>Dylan J. Foster, Alekh Agarwal, Miroslav Dudík, Haipeng
            Luo, Robert E. Schapire. Practical Contextual Bandits with
            Regression Oracles. ICML 2018.</li>
            <li>Alekh Agarwal, Miroslav Dudik, Satyen Kale, and John
            Langford, Contextual Bandit Learning with Predictable
            Rewards, AISTATS 2012.</li>
            <li>Dylan J. Foster, Alexander Rakhlin, David Simchi-Levi,
            Yunzong Xu. Instance-Dependent Complexity of Contextual
            Bandits and Reinforcement Learning: A Disagreement-Based
            Perspective. ArXiv 2020.</li>
            <li>David Simchi-Levi, Yunzong Xu. Bypassing the Monster: A
            Faster and Simpler Optimal Algorithm for Contextual Bandits
            under Realizability. ArXiv 2020.</li>
            </ul>
            <h4 id="implicit-regularization">Implicit
            regularization</h4>
            <ul>
            <li>Daniel Soudry, Elad Hoffer, Mor Shpigel Nacson, Suriya
            Gunasekar, Nathan Srebro. The Implicit Bias of Gradient
            Descent on Separable Data. JMLR 2018.</li>
            <li>Ziwei Ji, Matus Telgarsky. The implicit bias of gradient
            descent on nonseparable data. COLT 2019.</li>
            <li>Yuanzhi Li, Tengyu Ma, and Hongyang Zhang. Algorithmic
            Regularization in Over-parameterized Matrix Sensingand
            Neural Networks with Quadratic Activations. COLT 2018.</li>
            </ul>
            <h4 id="imitation-learning">Imitation learning</h4>
            <h5 id="interactive-imitation-learning">Interactive
            Imitation Learning</h5>
            <ul>
            <li>Hal Daumé III, John Langford, Daniel Marcu. Search-based
            Structured Prediction. Machine Learning Journal 2009.</li>
            <li>Stephane Ross, Drew Bagnell. Efficient Reductions for
            Imitation Learning. AISTATS 2010.</li>
            <li>Stephane Ross, Geoffrey J. Gordon, J. Andrew Bagnell. A
            Reduction of Imitation Learning and Structured Prediction to
            No-Regret Online Learning. AISTATS 2011.</li>
            <li>Stephane Ross, J. Andrew Bagnell. Reinforcement and
            Imitation Learning via Interactive No-Regret Learning.
            NeurIPS 2014.</li>
            <li>Wen Sun, Arun Venkatraman, Geoffrey J. Gordon, Byron
            Boots, J. Andrew Bagnell. Deeply AggreVaTeD: differentiable
            imitation learning for sequential prediction. ICML
            2017.</li>
            <li>Ching-An Cheng and Byron Boots. Convergence of Value
            Aggregation for Imitation Learning. AISTATS 2018.</li>
            <li>Wen Sun, Anirudh Vemula, Byron Boots, J. Andrew Bagnell.
            Provably Efficient Imitation Learning from Observation
            Alone. ICML 2019.</li>
            </ul>
            <h5
            id="apprenticeship-learning-and-inverse-reinforcement-learning">Apprenticeship
            Learning and Inverse Reinforcement Learning</h5>
            <ul>
            <li>Pieter Abbeel and Andrew Y. Ng. Apprenticeship Learning
            via Inverse Reinforcement Learning. ICML 2004.</li>
            <li>Brian D. Ziebart, Andrew Maas, J.Andrew Bagnell, Anind
            K. Dey. Maximum Entropy Inverse Reinforcement Learning. AAAI
            2008.</li>
            <li>Brian D. Ziebart, J.Andrew Bagnell, Anind K. Dey.
            Modeling Interaction via the Principle of Maximum Causal
            Entropy. ICML 2010.</li>
            <li>Umar Syed and Robert E. Schapire. A Game-Theoretic
            Approach to Apprenticeship Learning. NeurIPS 2007.</li>
            <li>Alekh Agarwal, Ashwinkumar Badanidiyuru, Miroslav Dudik,
            Robert Schapire, Aleksandrs Slivkins, Miro Dudík. Robust
            Multi-objective Learning with Mentor Feedback. COLT
            2014.</li>
            <li>Jonathan Ho, Stefano Ermon. Generative Adversarial
            Imitation Learning. NeurIPS 2016.</li>
            <li>Kareem Amin, Nan Jiang, Satinder Singh. Repeated Inverse
            Reinforcement Learning. NeurIPS 2017.</li>
            </ul>
            <h4 id="learning-under-fairness-constraints">Learning under
            Fairness Constraints</h4>
            <ul>
            <li>Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer
            Reingold and Richard Zemel. Fairness Through Awareness. ITCS
            2012.</li>
            <li>Moritz Hardt, Eric Price, Nathan Srebro. Equality of
            Opportunity in Supervised Learning. NeurIPS 2016.</li>
            <li>Alekh Agarwal, Alina Beygelzimer, Miroslav Dudík, John
            Langford, Hanna Wallach. A Reductions Approach to Fair
            Classification. ICML 2018.</li>
            <li>Michael Kearns, Seth Neel, Aaron Roth, Zhiwei Steven Wu.
            Preventing Fairness Gerrymandering: Auditing and Learning
            for Subgroup Fairness. ICML 2018.</li>
            </ul>
            <h4 id="machine-teaching-data-poisoning">Machine teaching /
            data poisoning</h4>
            <ul>
            <li>Jacob Steinhardt, Pang Wei Koh and Percy Liang.
            Certified Defenses for Data Poisoning Attacks. NeurIPS
            2017.</li>
            <li>Adversarial Attacks on Stochastic Bandits. Kwang-Sung
            Jun, Lihong Li, Yuzhe Ma, Xiaojin Zhu. NeurIPS 2018.</li>
            <li>Sanjoy Dasgupta, Daniel Hsu, Stefanos Poulis, Xiaojin
            Zhu. Teaching a black-box learner. ICML 2019.</li>
            <li>Xuezhou Zhang, Xiaojin Zhu, Laurent Lessard. Online Data
            Poisoning Attack. 2019.</li>
            <li>Yizhen Wang, Kamalika Chaudhuri. An Investigation of
            Data Poisoning Defenses for Online Learning. 2019.</li>
            </ul>
            <h4
            id="overparameterization-neural-network-learning">Overparameterization
            / neural network learning</h4>
            <ul>
            <li>Roi Livni, Shai Shalev-Shwartz, Ohad Shamir. On the
            Computational Efficiency of Training Neural Networks.
            NeurIPS 2014.</li>
            <li>Shai Shalev-Shwartz, Ohad Shamir, Shaked Shammah.
            Failures of gradient-based deep learning. ICML 2017.</li>
            <li>Mikhail Belkin, Daniel Hsu, Partha Mitra. Overfitting or
            perfect fitting? Risk bounds for classification and
            regression rules that interpolate. NeurIPS 2018.</li>
            <li>Yuanzhi Li and Yingyu Liang. Learning Overparameterized
            Neural Networks via Stochastic Gradient Descent on
            Structured Data. NeurIPS 2018.</li>
            <li>Zeyuan Allen-Zhu, Yuanzhi Li, Zhao Song. A Convergence
            Theory for Deep Learning via Over-Parameterization. ICML
            2019.</li>
            <li>Simon S. Du, Xiyu Zhai, Barnabas Poczos, Aarti Singh.
            Gradient Descent Provably Optimizes Over-parameterized
            Neural Networks. ICLR 2019.</li>
            <li>Sanjeev Arora, Simon S. Du, Wei Hu, Zhiyuan Li, Ruosong
            Wang. Fine-Grained Analysis of Optimization and
            Generalization for Overparameterized Two-Layer Neural
            Networks. ICML 2019.</li>
            </ul>
            <h4 id="pac-reinforcement-learning">PAC Reinforcement
            Learning</h4>
            <ul>
            <li>Michael Kearns and Satinder Singh. Near-Optimal
            Reinforcement Learning in Polynomial Time. Machine Learning,
            2002.</li>
            <li>Ronen I. Brafman and Moshe Tennenholtz. R-max – A
            General Polynomial Time Algorithm forNear-Optimal
            Reinforcement Learning. JMLR 2002.</li>
            <li>Sham Kakade. On the sample complexity of reinforcement
            learning. University of College London, 2003.</li>
            <li>Lihong Li, Michael L. Littman, Thomas J. Walsh,
            Alexander L. Strehl. Knows what it knows: a framework for
            self-aware learning. Machine Learning, 2011.</li>
            <li>Nan Jiang. <a
            href="http://nanjiang.cs.illinois.edu/files/cs598/note7.pdf">Notes
            on Rmax exploration.</a></li>
            <li>Christoph Dann, Tor Lattimore, Emma Brunskill. Unifying
            PAC and Regret: Uniform PAC Bounds for Episodic
            Reinforcement Learning. NeurIPS 2017.</li>
            <li>Chi Jin, Zeyuan Allen-Zhu, Sebastien Bubeck, Michael I.
            Jordan. Is Q-learning Provably Efficient? NeurIPS 2018.</li>
            <li>Andrea Zanette, Emma Brunskill. Tighter
            Problem-Dependent Regret Bounds in Reinforcement Learning
            without Domain Knowledge using Value Function Bounds. ICML
            2019.</li>
            </ul>
            <h4 id="theory-of-generative-modeling">Theory of generative
            modeling</h4>
            <ul>
            <li>Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, Yi
            Zhang. Generalization and Equilibrium in Generative
            Adversarial Nets (GANs). ICML 2017.</li>
            <li>Approximation and Convergence Properties of Generative
            Adversarial Learning. Shuang Liu, Olivier Bousquet, Kamalika
            Chaudhuri. NeurIPS 2017.</li>
            <li>Sanjeev Arora, Andrej Risteski, Yi Zhang. Do GANs learn
            the distribution? Some Theory and Empirics. ICLR 2018.</li>
            </ul>
            <h4 id="theory-of-lifelong-learning-meta-learning">Theory of
            lifelong learning / meta-learning</h4>
            <ul>
            <li>Mikhail Khodak, Maria-Florina Balcan, Ameet Talwalkar.
            Provable Guarantees for Gradient-Based Meta-Learning. ICML
            2019.</li>
            <li>Chelsea Finn, Aravind Rajeswaran, Sham Kakade, Sergey
            Levine. Online Meta-Learning. ICML 2019.</li>
            <li>Maria-Florina Balcan, Avrim Blum, Santosh Vempala.
            Efficient Representations for Life-Long Learning and
            Autoencoding. COLT 2015.</li>
            <li>Leonardo Cella, Alessandro Lazaric, Massimiliano Pontil.
            Meta-learning with Stochastic Linear Bandits. arXiv
            2020.</li>
            </ul>
            <h4 id="theory-of-llm-flnetuningalignment">Theory of LLM
            flnetuning/alignment</h4>
            <p>(updated: Mar 2025)</p>
            <ul>
            <li>huang et al., Correcting the Mythos of KL-Regularization
            ___.pdf</li>
            <li>munos et al., Nash Learning from Human Feedback.pdf</li>
            <li>gao et al., REBEL: Reinforcement Learning via Regressing
            Relative Rewards.pdf</li>
            <li>huang et al., Self-Improvement in Language Models: The
            Sharpening Mechanism</li>
            <li>xie et al., Exploratory Preference Optimization:
            Harnessing Implicit Q*-Approximation for Sample-Efficient
            RLHF</li>
            <li>azar et al., A General Theoretical Paradigm to
            Understand Learning from Human Preferences</li>
            </ul>
            </div>
    </div>
  </div>


  <script src="https://vjs.zencdn.net/5.4.4/video.js"></script>

</body>
</html>
