<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications</title>
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-106338466-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Kwang-Sung Jun</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="publication.html" class="current">Publications</a></div>
<div class="menu-item"><a href="research-group.html">Research&nbsp;Group</a></div>
<div class="menu-item"><a href="talk.html">Talks</a></div>
<div class="menu-item"><a href="artifact.html">Artifacts</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="personal.html">Personal&nbsp;Stuff</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
</div>
<p>Let me introduce frequently-appearing themes in my research as of January 2025.
I will identify a paper by (first author's last name) + (year) + (first word of the title).
</p>
<ul>
<li><p><b>Online learning as a theoretical/algorithmic tool (OL)</b>:
Online learning started from theoretical motivation, I believe, but it turns out to be a very useful tool for ML research such as deriving superior learning-theoretic guarantees, confidence bounds, and algorithms.
Interestingly, these results are often <i>nontrivial to obtain without online learning</i>!
</p>
<ul>
<li><p><tt>kuzborskij24better</tt>, <tt>orabona24tight</tt>, <tt>lee24improved</tt>, <tt>jun24noise</tt>, <tt>jang23tight</tt>, <tt>jun19kernel</tt>, <tt>jun17scalable</tt>
</p>
</li></ul>
</li>
<li><p><b>Instance-dependent guarantees (ID)</b>: 
If done right, this is a superior form of guarantee than the worst-case guarantee. 
At its best form, ID guarantees fully describe the performance of an algorithm as a function of the problem at hand.
Often, they reveal significantly accelerated rates compared to the worst-case guarantees, and some of these rates can only be achieved via carefully designed algorithms.
</p>
<ul>
<li><p><tt>nguyen24haver</tt>, <tt>zhao24adaptive</tt>, <tt>jang24efficient</tt>, <tt>zhao23revisiting</tt>, <tt>jang22popart</tt>
</p>
</li></ul>
</li>
<li><p><b>Parameter-free algorithms (PF)</b>: 
Many existing algorithms have a key hyperparameter that may lead to catastrophic failure when mistuned (e.g., learning rates in SGD). PF algorithms attempt to tune it automatically &ndash; more precisely, they provably adapts to the best hyperparameter automatically.
In a weaker form, they do not tune it precisely, but good enough that it would not hurt the performance too much.
</p>
<ul>
<li><p><tt>jun24noise</tt>, <tt>zhao23revisiting</tt>, <tt>gales22norm</tt>, <tt>jun19parameter</tt>, <tt>jun17improved</tt>, <tt>jun17online</tt>
</p>
</li>
</ul>

</li>
</ul>
<h2>Preprints</h2>
<p><b>Learning Explainable Dense Reward Shapes via Bayesian Optimization</b></br> 
Ryan Koo, Ian Yang, Vipul Raheja, Mingyi Hong, <font color=a92b13>Kwang-Sung Jun</font>, Dongyeop Kang</br>
<a href="https://arxiv.org/abs/2504.16272" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>Achieving adaptivity and optimality for multi-armed bandits using Exponential-Kullback Leiblier Maillard Sampling</b></br>
Hao Qin, <font color=a92b13>Kwang-Sung Jun</font>, Chicheng Zhang</br>
<a href="https://arxiv.org/abs/2502.14379" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>Improved Offline Contextual Bandits with Second-Order Bounds: Betting and Freezing</b></br> 
J. Jon Ryu, Jeongyeol Kwon, Benjamin Koppe, <font color=a92b13>Kwang-Sung Jun</font></br>
<a href="https://arxiv.org/abs/2502.10826" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>Fixing the Loose Brake: Exponential-Tailed Stopping Time in Best Arm Identification</b></br>
Kapilan Balagopalan, Tuan Ngo Nguyen, Yao Zhao, <font color=a92b13>Kwang-Sung Jun</font></br>
<a href="https://arxiv.org/abs/2411.01808" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<h2>2025</h2>
<p><b>HAVER: Instance-Dependent Error Bounds for Maximum Mean Estimation and Applications to Q-Learning</b></br>
Tuan Ngo Nguyen, Jay Barrett, <font color=a92b13>Kwang-Sung Jun</font></br>
In International Conference on Artificial Intelligence and Statistics (<b>AISTATS</b>), 2025</br> 
<a href="https://arxiv.org/abs/2411.00405" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>Minimum Empirical Divergence for Sub-Gaussian Linear Bandits</b></br>
Kapilan Balagopalan, <font color=a92b13>Kwang-Sung Jun</font></br>
In International Conference on Artificial Intelligence and Statistics (<b>AISTATS</b>), 2025</br> 
<a href="https://arxiv.org/abs/2411.00229" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<h2>2024</h2>
<p><b>A Unified Confidence Sequence for Generalized Linear Models, with Applications to Bandits</b></br>
Junghyun Lee, Se-Young Yun, and <font color=a92b13>Kwang-Sung Jun</font></br>
In Neural Information Processing Systems (<b>NeurIPS</b>), 2024</br>
<font color=C02A41><b>Oral presentation</b></font> at ICML&rsquo;24 Workshop on Aligning Reinforcement Learning Experimentalists and Theorists  </br>
<a href="https://arxiv.org/abs/2407.13977" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>Adaptive Experimentation When You Can't Experiment</b></br>
Yao Zhao, <font color=a92b13>Kwang-Sung Jun</font>, Tanner Fiez, Lalit Jain    </br>
In Neural Information Processing Systems (<b>NeurIPS</b>), 2024</br>   
<a href="https://arxiv.org/abs/2406.10738" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>Transfer Learning in Bandits with Latent Continuity</b></br>
Hyejin Park, Seiyun Shin, <font color=a92b13>Kwang-Sung Jun</font>, Jungseul Ok</br>
IEEE Transactions on Information Theory (<b>TIT</b>), 2024</br>
<a href="https://ieeexplore.ieee.org/document/10633753" target=&ldquo;blank&rdquo;>[official]</a>
</p>
<p><b>Better-than-KL PAC-Bayes Bounds</b></br>
Ilja Kuzborskij, <font color=a92b13>Kwang-Sung Jun</font>, Yulian Wu, Kyoungseok Jang, Francesco Orabona </br>
In Conference on Learning Theory (<b>COLT</b>), 2024</br>
<a href="https://proceedings.mlr.press/v247/kuzborskij24a.html" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/2402.09201" target=&ldquo;blank&rdquo;>[arxiv]</a> 
</p>
<p><b>Efficient Low-Rank Matrix Estimation, Experimental Design, and Arm-Set-Dependent Low-Rank Bandits</b></br>
Kyoungseok Jang, Chicheng Zhang, <font color=a92b13>Kwang-Sung Jun</font></br>
In International Conference on Machine Learning (<b>ICML</b>), 2024</br>
<a href="https://proceedings.mlr.press/v235/jang24e.html" target=&ldquo;blank&rdquo;>[official]</a> 
<a href="https://arxiv.org/abs/2402.11156" target=&ldquo;blank&rdquo;>[arxiv]</a> 
<a href="https://github.com/jajajang/lowpopart" target=&ldquo;blank&rdquo;>[code]</a> 
<a href="https://youtu.be/OWvxJ32n6ME?si=RHVWe4zyHOHjABzS" target=&ldquo;blank&rdquo;>[video]</a>
</p>
<p><b>Noise-Adaptive Confidence Sets for Linear Bandits and Application to Bayesian Optimization</b></br>
<font color=a92b13>Kwang-Sung Jun</font>, Jungtaek Kim </br>
In International Conference on Machine Learning (<b>ICML</b>), 2024</br>
<a href="https://proceedings.mlr.press/v235/jun24a.html" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/2402.07341" target=&ldquo;blank&rdquo;>[arxiv]</a> 
</p>
<p><b>Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion</b></br>
Junghyun Lee, Se-Young Yun, <font color=a92b13>Kwang-Sung Jun</font> </br>
In International Conference on Artificial Intelligence and Statistics (<b>AISTATS</b>), 2024</br> 
<a href="https://proceedings.mlr.press/v238/lee24d.html" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/2310.18554" target=&ldquo;blank&rdquo;>[arxiv]</a> 
<a href="https://github.com/nick-jhlee/logistic_bandit" target=&ldquo;blank&rdquo;>[code]</a>
</p>
<p><b>Tight Concentrations and Confidence Sequences from the Regret of Universal Portfolio</b></br>
Francesco Orabona, <font color=a92b13>Kwang-Sung Jun</font></br> 
IEEE Transactions on Information Theory (<b>TIT</b>), 2024</br>
<a href="https://ieeexplore.ieee.org/document/10315047" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/2110.14099" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<h2>2023</h2>
<p><b>Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards</b></br>
Hao Qin, <font color=a92b13>Kwang-Sung Jun</font>, Chicheng Zhang</br>  
In Neural Information Processing Systems (<b>NeurIPS</b>), 2023</br>   
<a href="https://papers.nips.cc/paper_files/paper/2023/hash/bdebb4549d5a79501bc151411abdb6d7-Abstract-Conference.html" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/2304.14989" target=&ldquo;blank&rdquo;>[arxiv]</a> 
<a href="https://openreview.net/forum?id=xF89MjFbWp&amp;referrer=%5Bthe%20profile%20of%20Chicheng%20Zhang%5D(%2Fprofile%3Fid%3D~Chicheng_Zhang1)" target=&ldquo;blank&rdquo;>[open review]</a>
</p>
<p><b>Revisiting Simple Regret: Fast Rates for Returning a Good Arm</b></br>
Yao Zhao, Connor Stephens, Csaba SzepesvaÃÅri, <font color=a92b13>Kwang-Sung Jun</font></br> 
In International Conference on Machine Learning (<b>ICML</b>), 2023</br>
<a href="https://proceedings.mlr.press/v202/zhao23g.html" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/2210.16913" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>Tighter PAC-Bayes Bounds Through Coin-Betting</b></br>
Kyoungseok Jang, <font color=a92b13>Kwang-Sung Jun</font>, Ilja Kuzborskij, Francesco Orabona (alphabetical order)</br>
In Conference on Learning Theory (<b>COLT</b>), 2023 </br>
<font color=C02A41><b>Oral presentation</b></font> at ICML&rsquo;23 Workshop on PAC-Bayes Meets Interactive Learning </br>
<a href="https://proceedings.mlr.press/v195/jang23a.html" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/2302.05829" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<h2>2022</h2>
<p><b>PopArt: Efficient Sparse Regression and Experimental Design for Optimal Sparse Linear Bandits</b></br>
Kyoungseok Jang, Chicheng Zhang, <font color=a92b13>Kwang-Sung Jun</font></br> 
In Neural Information Processing Systems (<b>NeurIPS</b>), 2022. </br>
<a href="https://papers.nips.cc/paper_files/paper/2022/hash/0e5cce15e1bfc6b3d7b71f24cc5da821-Abstract-Conference.html" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://openreview.net/forum?id=GWcdXz0M6a" target=&ldquo;blank&rdquo;>[openreview]</a>
<a href="https://arxiv.org/abs/2210.15345" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>Improved Regret Analysis for Variance-Adaptive Linear Bandits and Horizon-Free Linear Mixture MDPs</b></br>
Yeoneung Kim, Insoon Yang, <font color=a92b13>Kwang-Sung Jun</font></br> 
In Neural Information Processing Systems (<b>NeurIPS</b>), 2022</br>  
<a href="https://papers.nips.cc/paper_files/paper/2022/hash/078fa8f77ce55ef6e9cf79275b88acb0-Abstract-Conference.html" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://openreview.net/forum?id=U_YPSEyN2ls" target=&ldquo;blank&rdquo;>[openreview]</a>
<a href="https://arxiv.org/abs/2111.03289" target=&ldquo;blank&rdquo;>[arxiv]</a> 
</p>
<p><b>Jointly Efficient and Optimal Algorithms for Logistic Bandits</b></br>
Louis Faury, Marc Abeille, <font color=a92b13>Kwang-Sung Jun</font>, Cl√©ment Calauz√®nes</br> 
In International Conference on Artificial Intelligence and Statistics (<b>AISTATS</b>), 2022</br> 
<a href="https://proceedings.mlr.press/v151/faury22a.html" target=&ldquo;blank&rdquo;>[official]</a> <a href="https://arxiv.org/abs/2201.01985" target=&ldquo;blank&rdquo;>[arxiv]</a> 
</p>
<p><b>Norm-Agnostic Linear Bandits</b></br>
Spencer Brady Gales, Sunder Sethuraman, <font color=a92b13>Kwang-Sung Jun</font></br>
In International Conference on Artificial Intelligence and Statistics (<b>AISTATS</b>), 2022</br> 
<a href="https://proceedings.mlr.press/v151/gales22a.html" target=&ldquo;blank&rdquo;>[official]</a> <a href="https://arxiv.org/abs/2205.01257" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>Maillard Sampling: Boltzmann Exploration Done Optimally</b></br> 
Jie Bian, <font color=a92b13>Kwang-Sung Jun</font></br>
In International Conference on Artificial Intelligence and Statistics (<b>AISTATS</b>), 2022</br> 
<a href="https://proceedings.mlr.press/v151/bian22a.html" target=&ldquo;blank&rdquo;>[official]</a> <a href="https://arxiv.org/abs/2111.03290" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>An Experimental Design Approach for Regret Minimization in Logistic Bandits</b></br>
Blake Mason, <font color=a92b13>Kwang-Sung Jun</font>, Lalit Jain</br>  
In AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2022</br> 
<a href="https://ojs.aaai.org/index.php/AAAI/article/view/20741" target=&ldquo;blank&rdquo;>[official]</a> <a href="http://arxiv.org/abs/2202.02407" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<h2>2021</h2>
<p><b>Improved Confidence Bounds for the Linear Logistic Model and Applications to Bandits</b></br>
<font color=a92b13>Kwang-Sung Jun</font>, Lalit Jain, Blake Mason, Houssam Nassif</br> 
In International Conference on Machine Learning (<b>ICML</b>), 2021</br>
<a href="https://proceedings.mlr.press/v139/jun21a.html" target=&ldquo;blank&rdquo;>[official]</a>
</p>
<p><b>Improved Regret Bounds of Bilinear Bandits using Action Space Dimension Analysis</b></br>
Kyoungseok Jang, <font color=A92B13>Kwang-Sung Jun</font>, Se Young Yun, Wanmo Kang</br> 
In International Conference on Machine Learning (<b>ICML</b>), 2021</br>
<a href="https://proceedings.mlr.press/v139/jang21a.html" target=&ldquo;blank&rdquo;>[official]</a>
</p>
<p><b>Transfer Learning in Bandits with Latent Continuity</b></br>
Hyejin Park, Seiyun Shin, <font color=A92B13>Kwang-Sung Jun</font>, Jungseul Ok</br>
In IEEE International Symposium on Information Theory (<b>ISIT</b>), 2021</br>
<a href="https://ieeexplore.ieee.org/document/9518093" target=&ldquo;blank&rdquo;>[official]</a>
</p>
<h2>2020</h2>
<p><b>Crush Optimism with Pessimism: Structured Bandits Beyond Asymptotic Optimality</b></br>
<font color=A92B13>Kwang-Sung Jun</font>, Chicheng Zhang</br>
In Neural Information Processing Systems (<b>NeurIPS</b>), 2020</br>
<a href="https://proceedings.neurips.cc/paper/2020/hash/46489c17893dfdcf028883202cefd6d1-Abstract.html" target=&ldquo;blank&rdquo;>[official]</a> <a href="https://arxiv.org/abs/2006.08754" target=&ldquo;blank&rdquo;>[arxiv]</a> <a href="data/2020-crop-slides-rltheory.pdf" target=&ldquo;blank&rdquo;>[slides]</a>  <a href="https://www.youtube.com/watch?v=S8dluBz4lMU" target=&ldquo;blank&rdquo;>[video]</a>
</p>
<ul>
<li><p>Previously appeared in ICML Workshop on Theoretical Foundations of Reinforcement Learning, 2020.
</p>
</li>
</ul>
<h2>2019</h2>
<p><b>Parameter-Free Locally Differentially Private Stochastic Subgradient Descent</b></br>
<font color=A92B13>Kwang-Sung Jun</font>, Francesco Orabona</br>
In NeurIPS Workshop on Privacy in Machine Learning (<b>PriML</b>), 2019</br>
<a href="https://arxiv.org/abs/1911.09564" target=&ldquo;blank&rdquo;>[arxiv]</a> <a href="data/2019-priml-poster.pdf" target=&ldquo;blank&rdquo;>[poster]</a>
</p>
<p><b>Kernel Truncated Randomized Ridge Regression: Optimal Rates and Low Noise Acceleration</b></br>
<font color=A92B13>Kwang-Sung Jun</font>, Ashok Cutkosky, Francesco Orabona</br>
In Neural Information Processing Systems (<b>NeurIPS</b>), 2019</br>
<a href="https://papers.nips.cc/paper/9670-kernel-truncated-randomized-ridge-regression-optimal-rates-and-low-noise-acceleration" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/1905.10680" target=&ldquo;blank&rdquo;>[arxiv]</a> <a href="data/2019-kernel-slides.pdf" target=&ldquo;blank&rdquo;>[slides]</a> <a href="data/2019-kernel-poster.pdf" target=&ldquo;blank&rdquo;>[poster]</a>
</p>
<p><b>Parameter-Free Online Convex Optimization with Sub-Exponential Noise</b></br>
<font color=A92B13>Kwang-Sung Jun</font>, Francesco Orabona</br>
In Conference on Learning Theory (<b>COLT</b>), 2019</br>
<a href="http://proceedings.mlr.press/v99/jun19a.html" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/1902.01500" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>Bilinear Bandits with Low-rank Structure</b></br>
<font color=a92b13>Kwang-Sung Jun</font>, Rebecca Willett, Stephen Wright, Robert Nowak</br>
In International Conference on Machine Learning (<b>ICML</b>), 2019</br>
<a href="http://proceedings.mlr.press/v97/jun19a.html" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/1901.02470" target=&ldquo;blank&rdquo;>[arxiv]</a> 
<a href="https://github.com/kwangsungjun/lrbandit" target=&ldquo;blank&rdquo;>[code]</a>
</p>
<h2>2018</h2>
<p><b>Adversarial Attacks on Stochastic Bandits</b></br>
<font color=a92b13>Kwang-Sung Jun</font>, Lihong Li, Yuzhe Ma, Xiaojin Zhu</br>
In Neural Information Processing Systems (<b>NeurIPS</b>), 2018</br>
<a href="http://papers.nips.cc/paper/7622-adversarial-attacks-on-stochastic-bandits" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/1810.12188" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>Data Poisoning Attacks in Contextual Bandits</b></br>
Yuzhe Ma, <font color=a92b13>Kwang-Sung Jun</font>, Lihong Li, Xiaojin Zhu</br>
In Conference on Decision and Game Theory for Security (<b>GameSec</b>), 2018</br>
<a href="https://link.springer.com/chapter/10.1007/978-3-030-01554-1_11" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/1808.05760" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>Bayesian Active Learning on Graphs</b></br>
<font color=a92b13>Kwang-Sung Jun</font>, Robert Nowak</br> 
In Cooperative and Graph Signal Processing, Petar Djuric and Cedric Richard, Eds., Elsevier, 2018</br>
<a href="https://www.elsevier.com/books/cooperative-and-graph-signal-processing/djuric/978-0-12-813677-5" target=&ldquo;blank&rdquo;>[official]</a>
</p>
<h2>2017</h2>
<p><b>Online Learning for Changing Environments using Coin Betting</b></br>
<font color=a92b13>Kwang-Sung Jun</font>, Francesco Orabona, Stephen Wright, Rebecca Willett</br>
In Electronic Journal of Statistics (<b>EJS</b>), 2017</br>
<a href="https://projecteuclid.org/euclid.ejs/1513306874" target=&ldquo;blank&rdquo;>[official]</a>
</p>
<ul>
<li><p>[conference version]</br>
<b>Improved Strongly Adaptive Online Learning using Coin Betting</b></br>
<font color=a92b13>Kwang-Sung Jun</font>, Francesco Orabona, Stephen Wright, Rebecca Willett</br>
In International Conference on Artificial Intelligence and Statistics (<b>AISTATS</b>), 2017.  <font color=C02A41><b>Oral presentation</b></font></br>
<a href="http://proceedings.mlr.press/v54/jun17a.html" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/1610.04578" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
</li>
</ul>
<p><b>Scalable Generalized Linear Bandits: Online Computation and Hashing</b></br>
<font color=a92b13>Kwang-Sung Jun</font>, Aniruddha Bhargava, Robert Nowak, and Rebecca Willett</br>
In Neural Information Processing Systems (<b>NeurIPS</b>), 2017</br>
<a href="http://papers.nips.cc/paper/6615-scalable-generalized-linear-bandits-online-computation-and-hashing" target=&ldquo;blank&rdquo;>[official]</a>
<a href="https://arxiv.org/abs/1706.00136" target=&ldquo;blank&rdquo;>[arxiv]</a>
<a href="./data/code-gloc-20180510.zip" target=&ldquo;blank&rdquo;>[code]</a>
</p>
<p><b>Identifying Multiple Authors in a Binary Program</b></br>
Xiaozhu Meng, Barton P. Miller, and <font color=a92b13>Kwang-Sung Jun</font>. </br>
In European Symposium on Research in Computer Security (<b>ESORICS</b>),  2017</br>
<a href="https://link.springer.com/chapter/10.1007/978-3-319-66399-9_16" target=&ldquo;blank&rdquo;>[official]</a>
</p>
<h2>2016</h2>
<p><b>Graph-Based Active Learning: A New Look at Expected Error Minimization</b>. </br>
<font color=a92b13>Kwang-Sung Jun</font> and Robert Nowak</br>
In IEEE GlobalSIP Symposium on Non-Commutative Theory and Applications, 2016</br> 
<a href="http://ieeexplore.ieee.org/document/7906056/" target=&ldquo;blank&rdquo;>[ieee]</a>
<a href="https://arxiv.org/abs/1609.00845" target=&ldquo;blank&rdquo;>[arxiv]</a>
</p>
<p><b>U-INVITE: Estimating Individual Semantic Networks from Fluency Data</b></br>
Jeffrey Zemla, Yoed Kenett, <font color=a92b13>Kwang-Sung Jun</font>, and Joseph Austerweil. </br>
In Proceedings of the Annual Meeting of the Cognitive Science Society (<b>CogSci</b>), 2016</br>
<a href="https://alab.psych.wisc.edu/papers/files/Zemlaetal2016.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>
</p>
<p><b>Anytime Exploration for Multi-armed Bandits using Confidence Information</b></br>
<font color=a92b13>Kwang-Sung Jun</font> and Robert Nowak</br>
In International Conference on Machine Learning (<b>ICML</b>), 2016</br> 
<a href="https://proceedings.mlr.press/v48/jun16.html" target=&ldquo;blank&rdquo;>[official]</a> <a href="./data/jun16anytime-note.txt" target=&ldquo;blank&rdquo;>[post-publication note]</a>
</p>
<p><b>Top arm identification in multi-armed bandits with batch arm pulls</b>. </br>
<font color=a92b13>Kwang-Sung Jun</font>, Kevin Jamieson, Robert Nowak, and Xiaojin Zhu</br>
In International Conference on Artificial Intelligence and Statistics (<b>AISTATS</b>), 2016</br>
<a href="http://proceedings.mlr.press/v51/jun16.html" target=&ldquo;blank&rdquo;>[official]</a>
</p>
<h2>2015 and before</h2>
<p><b>Human memory search as initial-visit emitting random walk</b>. </br>
<font color=a92b13>Kwang-Sung Jun</font>, Xiaojin Zhu, Timothy Rogers, Zhuoran Yang, and Ming Yuan. </br>
In Neural Information Processing Systems (<b>NeurIPS</b>), 2015</br>
<a href="https://papers.nips.cc/paper_files/paper/2015/hash/dc6a70712a252123c40d2adba6a11d84-Abstract.html" target=&ldquo;blank&rdquo;>[official]</a>
</p>
<p><b>Smarter Crisis Crowdsourcing</b>. </br> 
Kayla Jacobs, <font color=a92b13>Kwang-Sung Jun</font>, Nathan Lieby, and Elena Eneva. </br>
In ACM SIGKDD Workshop on Data Science for Social Good, 2014</br> 
<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.664.29&amp;rep=rep1&amp;type=pdf" target=&ldquo;blank&rdquo;>[pdf]</a>
</p>
<p><b>Learning from Human-Generated Lists</b>. </br>
<font color=a92b13>Kwang-Sung Jun</font>, Xiaojin Zhu, Burr Settles, and Timothy Rogers</br> 
In International Conference on Machine Learning (<b>ICML</b>), 2013</br> 
<a href="https://proceedings.mlr.press/v28/jun13.html" target=&ldquo;blank&rdquo;>[official]</a>
<a href="./data/swirl_code_data_v2.zip" target=&ldquo;blank&rdquo;>[code&amp;data]</a> 
<a href="http://www.youtube.com/watch?v=V4TDynR2gPQ" target=&ldquo;blank&rdquo;>[video]</a>
</p>
<p><b>An Image-To-Speech iPad App</b>. </br>
Michael Maynord, Jitrapon Tiachunpun, Xiaojin Zhu, Charles R. Dyer, <font color=a92b13>Kwang-Sung Jun</font>, and Jake Rosin. </br>
Department of Computer Sciences Technical Report TR1774, University of Wisconsin-Madison, 2012.
</p>
<p><b>Learning from bullying traces in social media</b>. </br>
Jun-Ming Xu, <font color=a92b13>Kwang-Sung Jun</font>, Xiaojin Zhu, and Amy Bellmore</br> 
In the Conference of North American Chapter of the Association for Computational Linguistics: Human Language Technologies (<b>NAACL HLT</b>), 2012</br>
<a href="https://aclanthology.org/N12-1084/" target=&ldquo;blank&rdquo;>[official]</a>
</p>
<p><b>With a little help from the computer: Hybrid human-machine systems on bandit problems</b></br> 
Bryan Gibson, <font color=a92b13>Kwang-Sung Jun</font>, and Xiaojin Zhu. </br>
In NeurIPS Workshop on Computational Social Science and the Wisdom of Crowds, 2010. </br>
<a href="https://people.cs.umass.edu/~wallach/workshops/nips2010css/papers/gibson.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>
</p>
<p><b>Cognitive models of test-item effects in human category learning</b></br> 
Xiaojin Zhu, Bryan R. Gibson, <font color=a92b13>Kwang-Sung Jun</font>, Timothy T. Rogers, Joseph Harrison, and Chuck Kalish. </br>
In International Conference on Machine Learning (<b>ICML</b>), 2010. </br>
<a href="https://dl.acm.org/doi/abs/10.5555/3104322.3104480" target=&ldquo;blank&rdquo;>[acm digital library]</a>
<a href="http://pages.cs.wisc.edu/~jerryzhu/pub/tie.pdf" target=&ldquo;blank&rdquo;>[pdf]</a>
</p>
<p><b>An efficient collaborative filtering method based on k-nearest neighbor learning for large-scale data</b></br> 
<font color=a92b13>Kwang-Sung Jun</font> and Kyu-Baek Hwang. </br> 
In Proceedings of Korea Computer Congress, 2008.
</p>
<div id="footer">
<div id="footer-text">
Page generated 2025-04-30 22:23:26 MST, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
