# jemdoc: menu{MENU}{publication.html}
# jemdoc: analytics{UA-106338466-1}
= Publications

Let me introduce frequently-appearing themes in my research as of January 2025.
I will identify a paper by (first author's last name) \+ (year) \+ (first word of the title).

- *Online learning as a theoretical\/algorithmic tool (OL)*:
  Online learning started from theoretical motivation, I believe, but it turns out to be a very useful tool for ML research such as deriving superior learning-theoretic guarantees, confidence bounds, and algorithms.
  Interestingly, these results are often /nontrivial to obtain without online learning/!
  -- +kuzborskij24better+, +orabona24tight+, +lee24improved+, +jun24noise+, +jang23tight+, +jun19kernel+, +jun17scalable+
- *Instance-dependent guarantees (ID)*: 
  If done right, this is a superior form of guarantee than the worst-case guarantee. 
  At its best form, ID guarantees fully describe the performance of an algorithm as a function of the problem at hand.
  Often, they reveal significantly accelerated rates compared to the worst-case guarantees, and some of these rates can only be achieved via carefully designed algorithms.
  -- +nguyen24haver+, +zhao24adaptive+, +jang24efficient+, +zhao23revisiting+, +jang22popart+
- *Parameter-free algorithms (PF)*: 
  Many existing algorithms have a key hyperparameter that may lead to catastrophic failure when mistuned (e.g., learning rates in SGD). PF algorithms attempt to tune it automatically -- more precisely, they provably adapts to the best hyperparameter automatically.
  In a weaker form, they do not tune it precisely, but good enough that it would not hurt the performance too much.
  -- +jun24noise+, +zhao23revisiting+, +gales22norm+, +jun19parameter+, +jun17improved+, +jun17online+
  
# Below, I tried to group my key papers by topics along with tags describing particular aspects.
# 
# - confidence bounds/sets 
#   -- bounded random variables: +kuzborskij24better+ (OL), +orabona24tight+ (OL), +jang23tight+ (OL)
#   -- confidence sets: +jun24noise+ (OL), +lee24improved+ (OL), +lee24aunified+, +jun17scalable+ (OL)
# - multi-armed bandits
#   -- Maillard/MED type: +qin23kullback+, +bian22maillard+
#   -- pure exploration: +zhao23revisiting+ (PF, ID), +jun16top+
#   -- etc: +jun18adversarial+ (adversarial attack), +park24transfer+ (transfer learning)
# - contextual bandits
#   -- adaptivity (norm, noise-level, etc.): +jun24noise+ (\+bayesian optimization; PF, OL), +gales22norm+ (PF)
#   -- logistic/exponential family: +lee24aunified+ (OL), +lee24improved+, +faury22jointly+, +mason22anexperimental+, +jun21improved+ (\+dueling bandit), +jun17scalable+ (\+hashing)
#   -- sparsity/low-rank: +jang24efficient+ (ID), +jang22popart+ (ID), +jang21improved+, +jun19bilinear+
#   -- instrumental variable: +zhao24adaptive+ (ID)
#   -- generic hypothesis space: +jun20crush+
# - online learning
#   -- +jun19parameter+ (PF), +jun17improved+, +jun17online+
# - etc
#   -- +jun19kernel+ (kernel; OL)

#, +jun16graph+ (active learning)


== Preprints

  *Fixing the Loose Brake: Exponential-Tailed Stopping Time in Best Arm Identification*{{</br>}}
  Kapilan Balagopalan, Tuan Ngo Nguyen, Yao Zhao, {{<font color=a92b13>Kwang-Sung Jun</font></br>}}
  [https://arxiv.org/abs/2411.01808 \[arxiv\]]
  
== 2025

  *HAVER: Instance-Dependent Error Bounds for Maximum Mean Estimation and Applications to Q-Learning*{{</br>}}
  Tuan Ngo Nguyen, Jay Barrett, {{<font color=a92b13>Kwang-Sung Jun</font></br>}}
  In International Conference on Artificial Intelligence and Statistics (*AISTATS*), 2025{{</br>}} 
  [https://arxiv.org/abs/2411.00405 \[arxiv\]]

  *Minimum Empirical Divergence for Sub-Gaussian Linear Bandits*{{</br>}}
  Kapilan Balagopalan, {{<font color=a92b13>Kwang-Sung Jun</font></br>}}
  In International Conference on Artificial Intelligence and Statistics (*AISTATS*), 2025{{</br>}} 
  [https://arxiv.org/abs/2411.00229 \[arxiv\]]
  
== 2024

  *A Unified Confidence Sequence for Generalized Linear Models, with Applications to Bandits*{{</br>}}
  Junghyun Lee, Se-Young Yun, and {{<font color=a92b13>Kwang-Sung Jun</font></br>}}
  In Neural Information Processing Systems (*NeurIPS*), 2024{{</br>
  <font color=C02A41><b>Oral presentation</b></font>}} at ICML'24 Workshop on Aligning Reinforcement Learning Experimentalists and Theorists  {{</br>}}
  [https://arxiv.org/abs/2407.13977 \[arxiv\]]

  *Adaptive Experimentation When You Can't Experiment*{{</br>}}
  Yao Zhao, {{<font color=a92b13>Kwang-Sung Jun</font>}}, Tanner Fiez, Lalit Jain    {{</br>}}
  In Neural Information Processing Systems (*NeurIPS*), 2024{{</br>}}   
  [https://arxiv.org/abs/2406.10738 \[arxiv\]]

  *Transfer Learning in Bandits with Latent Continuity*{{</br>}}
  Hyejin Park, Seiyun Shin, {{<font color=a92b13>Kwang-Sung Jun</font>}}, Jungseul Ok{{</br>}}
  IEEE Transactions on Information Theory (*TIT*), 2024{{</br>}}
  [https://ieeexplore.ieee.org/document/10633753 \[official\]]

  *Better-than-KL PAC-Bayes Bounds*{{</br>}}
  Ilja Kuzborskij, {{<font color=a92b13>Kwang-Sung Jun</font>}}, Yulian Wu, Kyoungseok Jang, Francesco Orabona {{</br>}}
  In Conference on Learning Theory (*COLT*), 2024{{</br>}}
  [https://proceedings.mlr.press/v247/kuzborskij24a.html \[official\]]
  [https://arxiv.org/abs/2402.09201 \[arxiv\]] 

  *Efficient Low-Rank Matrix Estimation, Experimental Design, and Arm-Set-Dependent Low-Rank Bandits*{{</br>}}
  Kyoungseok Jang, Chicheng Zhang, {{<font color=a92b13>Kwang-Sung Jun</font></br>}}
  In International Conference on Machine Learning (*ICML*), 2024{{</br>}}
  [https://proceedings.mlr.press/v235/jang24e.html \[official\]] 
  [https://arxiv.org/abs/2402.11156 \[arxiv\]] 
  [https://github.com/jajajang/lowpopart \[code\]] 
  [https://youtu.be/OWvxJ32n6ME?si=RHVWe4zyHOHjABzS \[video\]]
  
  *Noise-Adaptive Confidence Sets for Linear Bandits and Application to Bayesian Optimization*{{</br>
  <font color=a92b13>Kwang-Sung Jun</font>}}, Jungtaek Kim {{</br>}}
  In International Conference on Machine Learning (*ICML*), 2024{{</br>}}
  [https://proceedings.mlr.press/v235/jun24a.html \[official\]]
  [https://arxiv.org/abs/2402.07341 \[arxiv\]] 

  *Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion*{{</br>}}
  Junghyun Lee, Se-Young Yun, {{<font color=a92b13>Kwang-Sung Jun</font>}} {{</br>}}
  In International Conference on Artificial Intelligence and Statistics (*AISTATS*), 2024{{</br>}} 
  [https://proceedings.mlr.press/v238/lee24d.html \[official\]]
  [https://arxiv.org/abs/2310.18554 \[arxiv\]] 
  [https://github.com/nick-jhlee/logistic_bandit \[code\]]

  *Tight Concentrations and Confidence Sequences from the Regret of Universal Portfolio*{{</br>}}
  Francesco Orabona, {{<font color=a92b13>Kwang-Sung Jun</font>}}{{</br>}} 
  IEEE Transactions on Information Theory (*TIT*), 2024{{</br>}}
  [https://ieeexplore.ieee.org/document/10315047 \[official\]]
  [https://arxiv.org/abs/2110.14099 \[arxiv\]]

== 2023

  *Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards*{{</br>}}
  Hao Qin, {{<font color=a92b13>Kwang-Sung Jun</font>}}, Chicheng Zhang{{</br>}}  
  In Neural Information Processing Systems (*NeurIPS*), 2023{{</br>}}   
  [https://papers.nips.cc/paper_files/paper/2023/hash/bdebb4549d5a79501bc151411abdb6d7-Abstract-Conference.html \[official\]]
  [https://arxiv.org/abs/2304.14989 \[arxiv\]] 
  [https://openreview.net/forum?id=xF89MjFbWp&referrer=%5Bthe%20profile%20of%20Chicheng%20Zhang%5D(%2Fprofile%3Fid%3D~Chicheng_Zhang1) \[open review\]]

  *Revisiting Simple Regret: Fast Rates for Returning a Good Arm*{{</br>}}
  Yao Zhao, Connor Stephens, Csaba Szepesvári, {{<font color=a92b13>Kwang-Sung Jun</font>}}{{</br>}} 
  In International Conference on Machine Learning (*ICML*), 2023{{</br>}}
  [https://proceedings.mlr.press/v202/zhao23g.html \[official\]]
  [https://arxiv.org/abs/2210.16913 \[arxiv\]]

  *Tighter PAC-Bayes Bounds Through Coin-Betting*{{</br>}}
  Kyoungseok Jang, {{<font color=a92b13>Kwang-Sung Jun</font>}}, Ilja Kuzborskij, Francesco Orabona (alphabetical order){{</br>}}
  In Conference on Learning Theory (*COLT*), 2023 {{</br>
  <font color=C02A41><b>Oral presentation</b></font>}} at ICML'23 Workshop on PAC-Bayes Meets Interactive Learning {{</br>}}
  [https://proceedings.mlr.press/v195/jang23a.html \[official\]]
  [https://arxiv.org/abs/2302.05829 \[arxiv\]]


== 2022

  *PopArt: Efficient Sparse Regression and Experimental Design for Optimal Sparse Linear Bandits*{{</br>}}
  Kyoungseok Jang, Chicheng Zhang, {{<font color=a92b13>Kwang-Sung Jun</font>}}{{</br>}} 
  In Neural Information Processing Systems (*NeurIPS*), 2022. {{</br>}}
  [https://papers.nips.cc/paper_files/paper/2022/hash/0e5cce15e1bfc6b3d7b71f24cc5da821-Abstract-Conference.html \[official\]]
  [https://openreview.net/forum?id=GWcdXz0M6a \[openreview\]]
  [https://arxiv.org/abs/2210.15345 \[arxiv\]]

  *Improved Regret Analysis for Variance-Adaptive Linear Bandits and Horizon-Free Linear Mixture MDPs*{{</br>}}
  Yeoneung Kim, Insoon Yang, {{<font color=a92b13>Kwang-Sung Jun</font>}}{{</br>}} 
  In Neural Information Processing Systems (*NeurIPS*), 2022{{</br>}}  
  [https://papers.nips.cc/paper_files/paper/2022/hash/078fa8f77ce55ef6e9cf79275b88acb0-Abstract-Conference.html \[official\]]
  [https://openreview.net/forum?id=U_YPSEyN2ls \[openreview\]]
  [https://arxiv.org/abs/2111.03289 \[arxiv\]] 

  *Jointly Efficient and Optimal Algorithms for Logistic Bandits*{{</br>}}
  Louis Faury, Marc Abeille, {{<font color=a92b13>Kwang-Sung Jun</font>}}, Clément Calauzènes{{</br>}} 
  In International Conference on Artificial Intelligence and Statistics (*AISTATS*), 2022{{</br>}} 
  [https://proceedings.mlr.press/v151/faury22a.html \[official\]] [https://arxiv.org/abs/2201.01985 \[arxiv\]] 

  *Norm-Agnostic Linear Bandits*{{</br>}}
  Spencer Brady Gales, Sunder Sethuraman, {{<font color=a92b13>Kwang-Sung Jun</font>}}{{</br>}}
  In International Conference on Artificial Intelligence and Statistics (*AISTATS*), 2022{{</br>}} 
  [https://proceedings.mlr.press/v151/gales22a.html \[official\]] [https://arxiv.org/abs/2205.01257 \[arxiv\]]
  
  *Maillard Sampling: Boltzmann Exploration Done Optimally*{{</br>}} 
  Jie Bian, {{<font color=a92b13>Kwang-Sung Jun</font>}}{{</br>}}
  In International Conference on Artificial Intelligence and Statistics (*AISTATS*), 2022{{</br>}} 
  [https://proceedings.mlr.press/v151/bian22a.html \[official\]] [https://arxiv.org/abs/2111.03290 \[arxiv\]]

  *An Experimental Design Approach for Regret Minimization in Logistic Bandits*{{</br>}}
  Blake Mason, {{<font color=a92b13>Kwang-Sung Jun</font>}}, Lalit Jain{{</br>}}  
  In AAAI Conference on Artificial Intelligence (*AAAI*), 2022{{</br>}} 
  [https://ojs.aaai.org/index.php/AAAI/article/view/20741 \[official\]] [http://arxiv.org/abs/2202.02407 \[arxiv\]]

== 2021

  *Improved Confidence Bounds for the Linear Logistic Model and Applications to Bandits*{{</br>
  <font color=a92b13>Kwang-Sung Jun</font>}}, Lalit Jain, Blake Mason, Houssam Nassif{{</br>}} 
  In International Conference on Machine Learning (*ICML*), 2021{{</br>}}
  [https://proceedings.mlr.press/v139/jun21a.html \[official\]]

  *Improved Regret Bounds of Bilinear Bandits using Action Space Dimension Analysis*{{</br>}}
  Kyoungseok Jang, {{<font color=A92B13>Kwang-Sung Jun</font>}}, Se Young Yun, Wanmo Kang{{</br>}} 
  In International Conference on Machine Learning (*ICML*), 2021{{</br>}}
  [https://proceedings.mlr.press/v139/jang21a.html \[official\]]

  *Transfer Learning in Bandits with Latent Continuity*{{</br>}}
  Hyejin Park, Seiyun Shin, {{<font color=A92B13>Kwang-Sung Jun</font>}}, Jungseul Ok{{</br>}}
  In IEEE International Symposium on Information Theory (*ISIT*), 2021{{</br>}}
  [https://ieeexplore.ieee.org/document/9518093 \[official\]]

== 2020

  *Crush Optimism with Pessimism: Structured Bandits Beyond Asymptotic Optimality*{{</br>
  <font color=A92B13>Kwang-Sung Jun</font>}}, Chicheng Zhang{{</br>}}
  In Neural Information Processing Systems (*NeurIPS*), 2020{{</br>}}
  [https://proceedings.neurips.cc/paper/2020/hash/46489c17893dfdcf028883202cefd6d1-Abstract.html \[official\]] [https://arxiv.org/abs/2006.08754 \[arxiv\]] [data/2020-crop-slides-rltheory.pdf \[slides\]]  [https://www.youtube.com/watch?v=S8dluBz4lMU \[video\]]
  - Previously appeared in ICML Workshop on Theoretical Foundations of Reinforcement Learning, 2020.
  
== 2019

  *Parameter-Free Locally Differentially Private Stochastic Subgradient Descent*{{</br>
  <font color=A92B13>Kwang-Sung Jun</font>}}, Francesco Orabona{{</br>}}
  In NeurIPS Workshop on Privacy in Machine Learning (*PriML*), 2019{{</br>}}
  [https://arxiv.org/abs/1911.09564 \[arxiv\]] [data/2019-priml-poster.pdf \[poster\]]

  *Kernel Truncated Randomized Ridge Regression: Optimal Rates and Low Noise Acceleration*{{</br>
  <font color=A92B13>Kwang-Sung Jun</font>}}, Ashok Cutkosky, Francesco Orabona{{</br>}}
  In Neural Information Processing Systems (*NeurIPS*), 2019{{</br>}}
  [https://papers.nips.cc/paper/9670-kernel-truncated-randomized-ridge-regression-optimal-rates-and-low-noise-acceleration \[official\]]
  [https://arxiv.org/abs/1905.10680 \[arxiv\]] [data/2019-kernel-slides.pdf \[slides\]] [data/2019-kernel-poster.pdf \[poster\]]

  *Parameter-Free Online Convex Optimization with Sub-Exponential Noise*{{</br>
  <font color=A92B13>Kwang-Sung Jun</font>}}, Francesco Orabona{{</br>}}
  In Conference on Learning Theory (*COLT*), 2019{{</br>}}
  [http://proceedings.mlr.press/v99/jun19a.html \[official\]]
  [https://arxiv.org/abs/1902.01500 \[arxiv\]]

  *Bilinear Bandits with Low-rank Structure*{{</br>
  <font color=a92b13>Kwang-Sung Jun</font>}}, Rebecca Willett, Stephen Wright, Robert Nowak{{</br>}}
  In International Conference on Machine Learning (*ICML*), 2019{{</br>}}
  [http://proceedings.mlr.press/v97/jun19a.html \[official\]]
  [https://arxiv.org/abs/1901.02470 \[arxiv\]] 
  [https://github.com/kwangsungjun/lrbandit \[code\]]

== 2018

  *Adversarial Attacks on Stochastic Bandits*{{</br>
  <font color=a92b13>Kwang-Sung Jun</font>}}, Lihong Li, Yuzhe Ma, Xiaojin Zhu{{</br>}}
  In Neural Information Processing Systems (*NeurIPS*), 2018{{</br>}}
  [http://papers.nips.cc/paper/7622-adversarial-attacks-on-stochastic-bandits \[official\]]
  [https://arxiv.org/abs/1810.12188 \[arxiv\]]

  *Data Poisoning Attacks in Contextual Bandits*{{</br>}}
  Yuzhe Ma, {{<font color=a92b13>Kwang-Sung Jun</font>}}, Lihong Li, Xiaojin Zhu{{</br>}}
  In Conference on Decision and Game Theory for Security (*GameSec*), 2018{{</br>}}
  [https://link.springer.com/chapter/10.1007/978-3-030-01554-1_11 \[official\]]
  [https://arxiv.org/abs/1808.05760 \[arxiv\]]

  *Bayesian Active Learning on Graphs*{{</br>
  <font color=a92b13>Kwang-Sung Jun</font>}}, Robert Nowak{{</br>}} 
  In Cooperative and Graph Signal Processing, Petar Djuric and Cedric Richard, Eds., Elsevier, 2018{{</br>}}
  [https://www.elsevier.com/books/cooperative-and-graph-signal-processing/djuric/978-0-12-813677-5 \[official\]]

== 2017

  *Online Learning for Changing Environments using Coin Betting*{{</br>
  <font color=a92b13>Kwang-Sung Jun</font>}}, Francesco Orabona, Stephen Wright, Rebecca Willett{{</br>}}
  In Electronic Journal of Statistics (*EJS*), 2017{{</br>}}
  [https://projecteuclid.org/euclid.ejs/1513306874 \[official\]]
  - \[conference version\]{{</br>}}
    *Improved Strongly Adaptive Online Learning using Coin Betting*{{</br>
    <font color=a92b13>Kwang-Sung Jun</font>}}, Francesco Orabona, Stephen Wright, Rebecca Willett{{</br>}}
    In International Conference on Artificial Intelligence and Statistics (*AISTATS*), 2017.  {{<font color=C02A41><b>Oral presentation</b></font>}}{{</br>}}
    [http://proceedings.mlr.press/v54/jun17a.html \[official\]]
    [https://arxiv.org/abs/1610.04578 \[arxiv\]]

  *Scalable Generalized Linear Bandits: Online Computation and Hashing*{{</br>
   <font color=a92b13>Kwang-Sung Jun</font>}}, Aniruddha Bhargava, Robert Nowak, and Rebecca Willett{{</br>}}
  In Neural Information Processing Systems (*NeurIPS*), 2017{{</br>}}
  [http://papers.nips.cc/paper/6615-scalable-generalized-linear-bandits-online-computation-and-hashing \[official\]]
  [https://arxiv.org/abs/1706.00136 \[arxiv\]]
  [./data/code-gloc-20180510.zip \[code\]]

  *Identifying Multiple Authors in a Binary Program*{{</br>}}
  Xiaozhu Meng, Barton P. Miller, and {{<font color=a92b13>Kwang-Sung Jun</font>}}. {{</br>}}
  In European Symposium on Research in Computer Security (*ESORICS*),  2017{{</br>}}
  [https://link.springer.com/chapter/10.1007/978-3-319-66399-9_16 \[official\]]

== 2016

  *Graph-Based Active Learning: A New Look at Expected Error Minimization*. {{</br>
  <font color=a92b13>Kwang-Sung Jun</font>}} and Robert Nowak{{</br>}}
  In IEEE GlobalSIP Symposium on Non-Commutative Theory and Applications, 2016{{</br>}} 
  [http://ieeexplore.ieee.org/document/7906056/ \[ieee\]]
  [https://arxiv.org/abs/1609.00845 \[arxiv\]]

  *U-INVITE: Estimating Individual Semantic Networks from Fluency Data*{{</br>}}
  Jeffrey Zemla, Yoed Kenett, {{<font color=a92b13>Kwang-Sung Jun</font>}}, and Joseph Austerweil. {{</br>}}
  In Proceedings of the Annual Meeting of the Cognitive Science Society (*CogSci*), 2016{{</br>}}
  [https://alab.psych.wisc.edu/papers/files/Zemlaetal2016.pdf \[pdf\]]

  *Anytime Exploration for Multi-armed Bandits using Confidence Information*{{</br>
  <font color=a92b13>Kwang-Sung Jun</font>}} and Robert Nowak{{</br>}}
  In International Conference on Machine Learning (*ICML*), 2016{{</br>}} 
  [https://proceedings.mlr.press/v48/jun16.html \[official\]] [./data/jun16anytime-note.txt \[post-publication note\]]

  *Top arm identification in multi-armed bandits with batch arm pulls*. {{</br>
  <font color=a92b13>Kwang-Sung Jun</font>}}, Kevin Jamieson, Robert Nowak, and Xiaojin Zhu{{</br>}}
  In International Conference on Artificial Intelligence and Statistics (*AISTATS*), 2016{{</br>}}
  [http://proceedings.mlr.press/v51/jun16.html \[official\]]

== 2015 and before

  *Human memory search as initial-visit emitting random walk*. {{</br>
  <font color=a92b13>Kwang-Sung Jun</font>}}, Xiaojin Zhu, Timothy Rogers, Zhuoran Yang, and Ming Yuan. {{</br>}}
  In Neural Information Processing Systems (*NeurIPS*), 2015{{</br>}}
  [https://papers.nips.cc/paper_files/paper/2015/hash/dc6a70712a252123c40d2adba6a11d84-Abstract.html \[official\]]

  *Smarter Crisis Crowdsourcing*. {{</br>}} 
  Kayla Jacobs, {{<font color=a92b13>Kwang-Sung Jun</font>}}, Nathan Lieby, and Elena Eneva. {{</br>}}
  In ACM SIGKDD Workshop on Data Science for Social Good, 2014{{</br>}} 
  [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.664.29&rep=rep1&type=pdf \[pdf\]]

  *Learning from Human-Generated Lists*. {{</br>
  <font color=a92b13>Kwang-Sung Jun</font>}}, Xiaojin Zhu, Burr Settles, and Timothy Rogers{{</br>}} 
  In International Conference on Machine Learning (*ICML*), 2013{{</br>}} 
  [https://proceedings.mlr.press/v28/jun13.html \[official\]]
  [./data/swirl_code_data_v2.zip \[code&data\]] 
  [http://www.youtube.com/watch?v=V4TDynR2gPQ \[video\]]

  *An Image-To-Speech iPad App*. {{</br>}}
  Michael Maynord, Jitrapon Tiachunpun, Xiaojin Zhu, Charles R. Dyer, {{<font color=a92b13>Kwang-Sung Jun</font>}}, and Jake Rosin. {{</br>}}
  Department of Computer Sciences Technical Report TR1774, University of Wisconsin-Madison, 2012.

  *Learning from bullying traces in social media*. {{</br>}}
  Jun-Ming Xu, {{<font color=a92b13>Kwang-Sung Jun</font>}}, Xiaojin Zhu, and Amy Bellmore{{</br>}} 
  In the Conference of North American Chapter of the Association for Computational Linguistics: Human Language Technologies (*NAACL HLT*), 2012{{</br>}}
  [https://aclanthology.org/N12-1084/ \[official\]]

  *With a little help from the computer: Hybrid human-machine systems on bandit problems*{{</br>}} 
  Bryan Gibson, {{<font color=a92b13>Kwang-Sung Jun</font>}}, and Xiaojin Zhu. {{</br>}}
  In NeurIPS Workshop on Computational Social Science and the Wisdom of Crowds, 2010. {{</br>}}
  [https://people.cs.umass.edu/~wallach/workshops/nips2010css/papers/gibson.pdf \[pdf\]]

  *Cognitive models of test-item effects in human category learning*{{</br>}} 
  Xiaojin Zhu, Bryan R. Gibson, {{<font color=a92b13>Kwang-Sung Jun</font>}}, Timothy T. Rogers, Joseph Harrison, and Chuck Kalish. {{</br>}}
  In International Conference on Machine Learning (*ICML*), 2010. {{</br>}}
  [https://dl.acm.org/doi/abs/10.5555/3104322.3104480 \[acm digital library\]]
  [http://pages.cs.wisc.edu/~jerryzhu/pub/tie.pdf \[pdf\]]

  *An efficient collaborative filtering method based on k-nearest neighbor learning for large-scale data*{{</br> 
  <font color=a92b13>Kwang-Sung Jun</font>}} and Kyu-Baek Hwang. {{</br>}} 
  In Proceedings of Korea Computer Congress, 2008.


